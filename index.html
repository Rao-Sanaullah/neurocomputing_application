<!DOCTYPE html>
<html lang="en">

<head>
  <!-- Required meta tags -->
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>The power of SNN in combination with transfer learning for object detection</title>
  
  <!-- Bootstrap -->
  <link href="css/bootstrap-4.4.1.css" rel="stylesheet">
  <link href="css/custom.css" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet" type="text/css">

  <link href="css/style.css" rel="stylesheet" type="text/css" media="all" />
  <!-- Bootstrap core CSS -->
  <link href="css/css/bootstrap.min.css" rel="stylesheet">


  <style>
    body {
      background: rgb(255, 255, 255) no-repeat fixed top left;
      font-family: 'Open Sans', sans-serif;
    }
  </style>

</head>
<!-- cover -->
<section>
  <div class="jumbotron text-center mt-0">
    <div class="container">
      <div class="row">
        <div class="col-12">
          <h2>A Novel Architecture that uses the Power of SNN in Combination with Transfer Learning for Real-time Object Detection
          </h2>
          <h4 style="color:#5a6268;">under-review</h4>
          <hr>
          <h6>
            <a href="https://github.com/Rao-Sanaullah" target="_blank">Sanaullah</a><sup>1*</sup>,
            <a href="#top">Shamini Koravuna</a><sup>2</sup>,
			<a href="#top">Ulrich Rückert</a><sup>2</sup>,
            <a href="#top">Thorsten Jungeblut</a><sup>1</sup>
          </h6>
          * Corresponding Author: Sanaullah
          <p><sup>1</sup>Industrial Internet of Things, Hochschule Bielefeld &nbsp;&nbsp;
            <sup>2</sup>Cognitronics & Sensor Systems, Universität Bielefeld
            <br>

          <div class="row justify-content-center">
            <div class="column">
              <p class="mb-5"><a class="btn btn-large btn-light"
                  href="#"
                  role="button" target="_blank">
                  <i class="fa fa-file"></i> Paper (under-review)</a> </p>
            </div>

            <div class="column">
              <p class="mb-5"><a class="btn btn-large btn-light" href="https://github.com/Rao-Sanaullah/neurocomputing_application_code"
                  role="button" target="_blank">
                  <i class="fa fa-github-alt"></i> Code</a> </p>
            </div>
          </div>

        </div>
      </div>
    </div>
  </div>
</section>



<!-- abstract -->
<section>
  <div class="container">
    <div class="row">
      <div class="col-12 text-center">
	    <section class="hand-crafted">
        <h3 class="w3l_header w3_agileits_header"><span>Abstract</span></h3>
        <hr style="margin-top:0px">
        <div class="row justify-content-center" style="align-items:center; display:flex;">
          <div class="col-md-12">
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="" id="header_vid">
              <source src="videos/comb.mp4" type="video/mp4">
            </video>
          </div>
        </div>
        <!-- <div class="col-md-6 img-responsive">
              <video width="70%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="" id="header_vid">
                    <source src="videos/neuconw-teaser-bg.m4v" type="video/mp4">
              </video>
            </div> -->
        <br>
		</section>
      </div>
                <p  align="justify"> This paper presents a novel architecture that combines Spiking Neural Networks (SNN) with transfer learning for real-time human presence detection using event-based cameras. 
		The architecture, deployed on edge computing devices (i.e. NVIDIA Jetson Xavier NX), integrates object detection, transfer learning with SNN, human recognition, localization, tracking, feature extraction, 
		multi-core processing, 
		and real-time analysis. It efficiently adapts pre-trained Convolutional Neural Network (CNN) weights to SNNs, allowing event-driven processing, and maintains a spike train dataset for object information. 
		The architecture is adaptable for applications in security, surveillance, and behavioral research. Extensive real-time testing demonstrates its robustness and adaptability in dynamic environments.</p>


      </p>
    </div>
  </div>
  </div>
</section>
<br>

<!-- method overview -->
<section>
  <div class="container">
    <div class="row">
      <div class="col-12 text-center">
		<h3 class="w3l_header w3_agileits_header"><span>Method Overview</span></h3>
        <hr style="margin-top:0px">
        <div class="row justify-content-center" style="align-items:center; display:flex;">
          <div class="col-md-12">
            <img width="80%" src="images/learning.png" alt="method_overview" class="img-fluid">
          </div>
        </div>
        <br>
      </div>
      <p class="text-justify">
        The execution methodology of the proposed neuromorphic computing application. The execution
structure represents the transfer of learning from a CNN to a Spiking Model of the LIF Neural Model.
Real-time implementation is utilized for object detection with new data, which is then stored in a Spike
Train for future predictions using the Spiking Model.
      </p>
    </div>
  </div>
  </div>
</section>
<br>

<!-- qualitative results -->
<section>
  <div class="col-md-12 text-center">
	<h3 class="w3l_header w3_agileits_header"><span>Qualitative Results</span></h3>
      <hr style="margin-top:0px">
      <!-- additional notes -->
      <div style="display: inline-block; text-align: left;">
        <p style="color: #808080;">
		          <h6 class="w3l_header" style="font-size: 20px;"> Spike Vision Approach for Generating Large-Scale Spiking Dataset </h6>
        </p>
      </div>
      <br>
      



    <!-- row-2 option-2 (mesh & fg rendering) -->
    <div class="d-flex justify-content-center align-items-end">
        <!-- mesh -->
        <div class="col-lg-4 col-md-6 col-sm-12 text-center">
            <img src="images/3d.png" alt="input" class="img-fluid">
        </div>
        <!-- rendering (video) -->
        <div class="col-lg-4 col-md-6 col-sm-12 text-center">
            <div class="embed-responsive embed-responsive-16by9">

			<video " playsinline="" autoplay="autoplay" loop="loop" preload="" muted="" id="header_vid">
              <source src="videos/3d.mp4" type="video/mp4">
            </video>
			
            </div>

        </div>

    </div>
	      <br>
	      <div style="display: inline-block; text-align: left;">
        <p style="color: #808080;">
          * This 3D plot offers a visual representation of detected humans along with their corresponding spike trains. <br>
          * The right image illustrates the data of the first 25 objects along with 0-75 objects, <br>
		  * And the right 3d plot provides an overview of the data from first 100 detected objects.
        </p>
      </div>
	  
	       <br>
	  
	        <br>
	  
	  
	  
	  
	  
	  
	  
	  
	  
	  
    <!-- row-3 option-2 (mesh & fg rendering) -->
    <div class="d-flex justify-content-center align-items-end">
        <!-- mesh -->

        <!-- rendering (video) -->
        <div class="col-lg-8 col-md-12 col-sm-12 text-center">
			<p " playsinline="" autoplay="autoplay" loop="loop" preload="" muted="" id="header_vid">
              <img src="videos/spike.gif" >
            </p>

        </div>
 
	  
    </div>
	      <br>
	      <div style="display: inline-block; text-align: left;">
        <p style="color: #808080;">
          * This plot offers a visual representation of spike trains dataset based on the activity of multiple neurons over-time. <br>
          * Neurons are represented along the y-axis, and time is along the x-axis.<br>
		  * Each spike (i.e., action potential) of a neuron is marked as a dot at its corresponding time of occurrence.
        </p>
      </div>
	  
	       <br> 
	  
      <div style="display: inline-block; text-align: left;">
        <p style="color: #808080;">
          <h6 class="w3l_header" style="font-size: 25px;"> Computational Cost Efficiency </h6><br>
        </p>
      </div>
      <br>
      
	  
	  
	  
	  
	  
	  
	  
	  
	  
	  
    <!-- row-4 option-2 (mesh & fg rendering) -->
    <div class="d-flex justify-content-center align-items-end">
        <!-- mesh -->
        <div class="col-lg-4 col-md-6 col-sm-12 text-center">
            <img src="images/cost.png" alt="input" class="img-fluid">
        </div>
        <!-- rendering (video) -->
        <div class="col-lg-4 col-md-6 col-sm-12 text-center">
            <div class="embed-responsive embed-responsive-16by9">

			<video " playsinline="" autoplay="autoplay" loop="loop" preload="" muted="" id="header_vid">
              <source src="videos/com.mp4" type="video/mp4">
            </video>
			
            </div>

        </div>

    </div>
	      <br>
	      <div style="display: inline-block; text-align: left;">
        <p style="color: #808080;">
          * Computational cost efficiency comparison of the system between object detection and no object detection. <br>
          * The system’s computational cost remains at a minimum state during periods of inactivity.<br>
		  * Object detection, on the other hand, raises the computing cost, as indicated by ’Object Detected’.
        </p>
      </div>
	  

      <br>


  </div>
</section>
<br>

<!-- citing -->
<div class="container">
  <div class="row ">
    <div class="col-12">
      <h3>Citation</h3>
      <hr style="margin-top:0px">
      <pre style="background-color: #e9eeef;padding: 1.25em 1.5em">
<code>Upcoming</code></pre>
    </div>
  </div>
</div>

<!-- ack -->
<!-- <div class="container">
    <div class="row ">
      <div class="col-12">
          <h3>Acknowledgements</h3>
          <hr style="margin-top:0px">
          <p class="text-justify">
          </p>
      </div>
    </div>
  </div> -->


<footer class="text-center" style="margin-bottom:10px; font-size: medium;">
  <hr>
<p>© 2023 IIOT Lab - Hochschule Bielefeld (HSBI). All Rights Reserved | Design by <a href="https://github.com/Rao-Sanaullah">Sanaullah</a></p>
</footer>

</body>

</html>
